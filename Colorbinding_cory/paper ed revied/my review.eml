Received: from iport-c1-out.ucsd.edu (132.239.0.176) by
 XCORE-TPCS2.AD.UCSD.EDU (132.239.0.204) with Microsoft SMTP Server (TLS) id
 14.1.355.3; Mon, 17 Dec 2012 22:02:11 -0800
X-IronPort-Delayed-Alias: True
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: AhgCAFAF0FDRVdyrlGdsb2JhbABFDr4bCBYOAQEBAQkJCwkSKYJlARseAxIQA1oBEQEFAQYQDIgTAQMPmR2CbYwzgnuFBQoZJw1ZiHYBBQyOLIJcA4hhjSmOaBYpg1YxLg
X-IronPort-AV: E=Sophos;i="4.84,307,1355126400"; 
   d="scan'208";a="935725349"
X-Spam-Status: No
X-Spam-Level:
Received: from mail-vc0-f171.google.com ([209.85.220.171])  by
 iport-c1-in.ucsd.edu with ESMTP/TLS/RC4-SHA; 17 Dec 2012 22:02:11 -0800
Received: by mail-vc0-f171.google.com with SMTP id n11so343406vch.2        for
 <crieth@ucsd.edu>; Mon, 17 Dec 2012 22:02:10 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=0SzoLF0m1IwHl3d5OT/Rbg7T62iCLpP5WYd/GD3+GiE=;
        b=ozbGde0Ra5r1FAhd0W/WG2BqkEhO+B7dStFvLKAMXyY194JUnNqbCfrX/josqCMipH
         /TCRUl+Q5KMXOkPpO2bkwCMslOWatYSPZRiKh4woyojqqKV1O27HkpH+VqTFk7NHiSiR
         e6Q6YaYMZpeSYiARBuBnifjKGzTUQUeWwY0wx+mpUl6/+vEmM0yETml1takFiG6prktr
         MpKZSC3XANwTkirNrolLN8ebAq010famKfvlnCNlNsyaPJUDzeDMPO8dbtLQrhO83Pd2
         ufaF03apBAvQP9C2i2gbF0lTQHmOL3gDYY8l4P24kcLMK26I2ckqi35K7CScZZyD7pgJ
         5qOg==
Received: by 10.52.38.163 with SMTP id h3mr1158973vdk.35.1355810530090; Mon,
 17 Dec 2012 22:02:10 -0800 (PST)
Received: by 10.58.209.38 with HTTP; Mon, 17 Dec 2012 22:02:09 -0800 (PST)
Date: Mon, 17 Dec 2012 22:02:09 -0800
Message-ID: <CA+T5Hkjn8iGgfKZjByq=oaa_QDh=c2o8hRxvr=kHjHzH0sb+_Q@mail.gmail.com>
Subject: my review
From: Ed Vul <edwardvul@gmail.com>
To: Cory Rieth <crieth@ucsd.edu>
Content-Type: multipart/alternative; boundary="bcaec51ddc69075f3904d11a3d24"
Return-Path: edwardvul@gmail.com
X-MS-Exchange-Organization-AuthSource: XCORE-TPCS2.AD.UCSD.EDU
X-MS-Exchange-Organization-AuthAs: Anonymous
X-MS-Exchange-Organization-AVStamp-Mailbox: MSFTFF;1;0;0 0 0
MIME-Version: 1.0

--bcaec51ddc69075f3904d11a3d24
Content-Type: text/plain; charset="ISO-8859-1"

....of that paper I just sent you

note point 1 and the final parenthetical -- this seems like there is
*something* there that would make interesting predictions in our
hierarchical binding tasks, but I can't quite put my finger on it.

Ed


Apologies for the three day delay with this review.

The authors present two sets of experiments. In 1,2 they replicate the
'integral features' finding that it is hard to compare luminance across
objects with different hues (E1), or area across different shapes (E2).  In
Expts 3-5, the authors compared memory fidelity for one objects, to that
for two similar objects (matched on an integral feature), to that for two
different objects (differing in integral features -- hue in E3, shape in
E4, pitch in E5).  They assessed memory fidelity by the precision
(reciprocal of standard deviation) of the best-fitting cumulative normal
psychometric function to change detection performance as luminance (E3),
area (E4), or amplitude (E5) of a test probe was varied relative to the
true value.  In all three experiments, the precision for two items drops
relative to one item, but when the two items are made to be sufficiently
different, they appear to be represented as precisely as a single item
alone.  These results are cool, and should be published.  I have some minor
questions that may be useful to guide clarifications in the paper, but
nothing that merits more than a minor revision without any need to send it
back to me.

1) I was quite surprised by the finding that this only works for integral
features, and would have liked to see some more speculation about why this
makes sense.  (a priori, I would have guessed that this should work with
any means of making the two objects sufficiently distinct).  However, Expt
3 and 4 suggest that the same method of making objects distinct (hue
changes) helps if the reported feature is color, but not if it is area.
 This seems to imply not only that integral features are jointly
represented, but also that having jointly represented features helps solve
the correspondence problem somehow?  Or is it that the probe includes one
of the conjointly represented features?  Anyway, the interpretation of why
this integral feature manipulation should work is not spelled out
particularly clearly, and it would be nice to hear the author's opinions.

2) What does this have to do with memory?  It seems to me that these
experiments show clearly that a large amount of error introduced when going
from one- to two-item displays in a vstm task arises from some misbinding
or correspondence problem errors either during encoding or retrieval (that
the integral feature manipulation can resolve).  Would the authors suggest
that such correspondence errors are the *only* source of error in all vstm
tasks (even as the number of items grows to be very large)?  If so, perhaps
they might speculate how their interpretation can be reconciled with the
larger body of vstm literature, and what limits vstm fidelity (to be lower
than simple perceptual fidelilty) in the first place.  If not, perhaps they
might speculate about when (at four items? eight?) other kinds of vstm
limitations might start creeping in.  In general, this is a great
demonstration of the role correspondence errors play in typical vstm tasks,
but it would be nice to know how these correspondence errors relate to the
larger patterns of performance in the vstm literature.

Anyway -- I think this paper is great, and should be published.  I see no
technical faults in the design and results, and I will not nitpick the
details.

(btw, to highlight the intriguing result that the particular combination of
report and distinguishing feature required to alleviate the correspondence
problem, they might consider running a hybrid of experiment 3 and 4, where
objects vary in shape, hue, luminance, and size, and that shape and hue
only have a beneficial effect in the two-item condition when the
corresponding report feature is relevant.  They might even use such a
design to figure out whether this integral feature advantage happens in
encoding or decoding by not revealing to the subjects which dimension will
need to be reported until the probe trial appears.)

--bcaec51ddc69075f3904d11a3d24
Content-Type: text/html; charset="ISO-8859-1"
Content-Transfer-Encoding: quoted-printable

<meta http-equiv=3D"Content-Type" content=3D"text/html; charset=3Diso-8859-=
1">....of that paper I just sent you<div><br></div><div>note point 1 and th=
e final parenthetical -- this seems like there is *something* there that wo=
uld make interesting predictions in our hierarchical binding tasks, but I c=
an't quite put my finger on it.</div>
<div><br></div><div>Ed</div><div><br><div><br></div><div><div>Apologies for=
 the three day delay with this review.</div><div><br></div><div>The authors=
 present two sets of experiments. In 1,2 they replicate the 'integral featu=
res' finding that it is hard to compare luminance across objects with diffe=
rent hues (E1), or area across different shapes (E2). &nbsp;In Expts 3-5, t=
he authors compared memory fidelity for one objects, to that for two simila=
r objects (matched on an integral feature), to that for two different objec=
ts (differing in integral features -- hue in E3, shape in E4, pitch in E5).=
 &nbsp;They assessed memory fidelity by the precision (reciprocal of standa=
rd deviation) of the best-fitting cumulative normal psychometric function t=
o change detection performance as luminance (E3), area (E4), or amplitude (=
E5) of a test probe was varied relative to the true value. &nbsp;In all thr=
ee experiments, the precision for two items drops relative to one item, but=
 when the two items are made to be sufficiently different, they appear to b=
e represented as precisely as a single item alone. &nbsp;These results are =
cool, and should be published. &nbsp;I have some minor questions that may b=
e useful to guide clarifications in the paper, but nothing that merits more=
 than a minor revision without any need to send it back to me.</div>
<div><br></div><div>1) I was quite surprised by the finding that this only =
works for integral features, and would have liked to see some more speculat=
ion about why this makes sense. &nbsp;(a priori, I would have guessed that =
this should work with any means of making the two objects sufficiently dist=
inct). &nbsp;However, Expt 3 and 4 suggest that the same method of making o=
bjects distinct (hue changes) helps if the reported feature is color, but n=
ot if it is area. &nbsp;This seems to imply not only that integral features=
 are jointly represented, but also that having jointly represented features=
 helps solve the correspondence problem somehow? &nbsp;Or is it that the pr=
obe includes one of the conjointly represented features? &nbsp;Anyway, the =
interpretation of why this integral feature manipulation should work is not=
 spelled out particularly clearly, and it would be nice to hear the author'=
s opinions. &nbsp;</div>
<div><br></div><div>2) What does this have to do with memory? &nbsp;It seem=
s to me that these experiments show clearly that a large amount of error in=
troduced when going from one- to two-item displays in a vstm task arises fr=
om some misbinding or correspondence problem errors either during encoding =
or retrieval (that the integral feature manipulation can resolve). &nbsp;Wo=
uld the authors suggest that such correspondence errors are the *only* sour=
ce of error in all vstm tasks (even as the number of items grows to be very=
 large)? &nbsp;If so, perhaps they might speculate how their interpretation=
 can be reconciled with the larger body of vstm literature, and what limits=
 vstm fidelity (to be lower than simple perceptual fidelilty) in the first =
place. &nbsp;If not, perhaps they might speculate about when (at four items=
? eight?) other kinds of vstm limitations might start creeping in. &nbsp;In=
 general, this is a great demonstration of the role correspondence errors p=
lay in typical vstm tasks, but it would be nice to know how these correspon=
dence errors relate to the larger patterns of performance in the vstm liter=
ature.</div>
<div><br></div><div>Anyway -- I think this paper is great, and should be pu=
blished. &nbsp;I see no technical faults in the design and results, and I w=
ill not nitpick the details. &nbsp;</div><div><br></div><div>(btw, to highl=
ight the intriguing result that the particular combination of report and di=
stinguishing feature required to alleviate the correspondence problem, they=
 might consider running a hybrid of experiment 3 and 4, where objects vary =
in shape, hue, luminance, and size, and that shape and hue only have a bene=
ficial effect in the two-item condition when the corresponding report featu=
re is relevant. &nbsp;They might even use such a design to figure out wheth=
er this integral feature advantage happens in encoding or decoding by not r=
evealing to the subjects which dimension will need to be reported until the=
 probe trial appears.)</div>
</div><div><br></div></div>

--bcaec51ddc69075f3904d11a3d24--
