M <- matrix(rep(m, each=n), ncol=d)
L <- matrix(rnorm(k*n), ncol=k)
W <- rbind(c(1,1,1,0,0), c(0,0,1,1,1))
# W <- matrix(rnorm(d*k), ncol=d)
Y <- M + L%*%W
Y
ggpairs(as.data.frame(Y))
a.svd <- svd(Y)
a.svd$d
a.svd$u
a.svd$v
rnorm(n*d, Y, sd=1)
noise.sd = rep(1, d)
apply(matrix(rnorm(n*d,0,noise.sd), ncol=d), 1, var)
apply(matrix(rnorm(n*d,0,noise.sd), ncol=d), 2, var)
m = c(5,4,3,2,1,0.5)
noise.sd = c(5,4,3,2,1,0.5) #rep(1, d)
apply(matrix(rnorm(n*d,0,noise.sd), ncol=d), 2, var)
apply(matrix(rnorm(n*d,0,noise.sd), ncol=d, byrow = T), 2, var)
apply(matrix(rnorm(n*d,0,noise.sd), ncol=d, byrow = F), 2, var)
noise.sd
apply(matrix(rnorm(n*d,0,noise.sd), ncol=d, byrow = F), 2, sd)
apply(matrix(rnorm(n*d,0,noise.sd), ncol=d, byrow = T), 2, sd)
rnorm(n*d,0,noise.sd)
apply(matrix(rnorm(n*d,0,noise.sd), ncol=d, bycol = T), 2, sd)
apply(matrix(rnorm(n*d,0,noise.sd), ncol=d, byrow = T), 2, sd)
apply(matrix(rnorm(n*d,0,noise.sd), ncol=d, byrow = F), 2, sd)
n = 10
d = 2
noise.sd = c(5,1)
rnorm(n*d,0,noise.sd)
m = c(10,-10)
rnorm(n*d,m,0.1)
matrix(rnorm(n*d,m,0.1), ncol=d)
matrix(rnorm(n*d,m,0.1), ncol=d, byrow=T)
n = 100 # number of observations
k = 2   # number of latent dimensions
d = 5
noise.sd = c(5,4,3,2,1,0.5) #rep(1, d)
m = seq(-100, 100, length.out=d)
matrix(rnorm(n*d,m,0.1), ncol=d, byrow=T)
matrix(rnorm(n*d,0,noise.sd), ncol=d, byrow=T)
noise.sd = c(5,0.1,1,0.1,10,0.1) #rep(1, d)
matrix(rnorm(n*d,0,noise.sd), ncol=d, byrow=T)
noise.sd = c(50,0.1,1,0.1,10,0.1) #rep(1, d)
noise.sd = c(50,0.1,1,0.1,10) #rep(1, d)
matrix(rnorm(n*d,0,noise.sd), ncol=d, byrow=T)
noise.sd = c(5,4,3,2,1) #rep(1, d)
apply(matrix(rnorm(n*d,0,noise.sd), ncol=d, byrow = T), 2, sd)
matrix(rnorm(n*d,0,noise.sd), ncol=d, byrow=T)
noise.sd = c(5,4,3,2,1) #rep(1, d)
matrix(rnorm(n*d,0,noise.sd), ncol=d, byrow=T)
apply(matrix(rnorm(n*d,0,noise.sd), ncol=d, byrow = T), 2, sd)
noise.sd = rep(0.01, d) # c(5,4,3,2,1)
n = 100 # number of observations
k = 2   # number of latent dimensions
d = 5
noise.sd = rep(0.01, d) # c(5,4,3,2,1)
m = rep(0, d)
W <- rbind(c(1,1,1,0,0), c(0,0,1,1,1))
M <- matrix(rep(m, each=n), ncol=d)
L <- matrix(rnorm(k*n), ncol=k)
Y <- M + L%*%W + matrix(rnorm(n*d,0,noise.sd), ncol=d, byrow=T)
y
ggpairs(as.data.frame(Y))
a.svd <- svd(Y)
plot(a.svd$d)
a.svd$v
W
n = 1000 # number of observations
k = 2   # number of latent dimensions
d = 5
noise.sd = rep(0.01, d) # c(5,4,3,2,1)
m = rep(0, d)
W <- rbind(c(1,1,1,0,0), c(0,0,1,1,1))
M <- matrix(rep(m, each=n), ncol=d)
L <- matrix(rnorm(k*n), ncol=k)
Y <- M + L%*%W + matrix(rnorm(n*d,0,noise.sd), ncol=d, byrow=T)
a.svd <- svd(Y)
plot(a.svd$d)
a.svd$v
a.pca <- prcomp(Y, center=T, scale=T)
plot(a.pca$sdev)
a.pca$rotation
a.svd <- svd(whiten(Y))
whiten(Y)
z.score = function(X){
apply(X, 2, function(x){(x-mean(x))/sd(x)})
}
z.score(X)
z.score(Y)
a.svd <- svd(z.score(Y))
plot(a.svd$d)
a.svd$v
cor(Y)
n = 1000 # number of observations
k = 2   # number of latent dimensions
d = 5
noise.sd = rep(0.01, d) # c(5,4,3,2,1)
m = rep(0, d)
W <- rbind(c(1,1,1,0,0), c(0,0,1,1,1))
M <- matrix(rep(m, each=n), ncol=d)
L <- matrix(rnorm(k*n), ncol=k)
Y <- M + L%*%W + matrix(rnorm(n*d,0,noise.sd), ncol=d, byrow=T)
cor(Y)
n = 1000 # number of observations
k = 2   # number of latent dimensions
d = 5
noise.sd = rep(0, d) # c(5,4,3,2,1)
m = rep(0, d)
W <- rbind(c(1,1,1,0,0), c(0,0,1,1,1))
M <- matrix(rep(m, each=n), ncol=d)
L <- matrix(rnorm(k*n), ncol=k)
Y <- M + L%*%W + matrix(rnorm(n*d,0,noise.sd), ncol=d, byrow=T)
cor(Y)
cor(L%*%W)
W
L <- matrix(rnorm(k*n), ncol=k, byrow = T)
Y <- M + L%*%W + matrix(rnorm(n*d,0,noise.sd), ncol=d, byrow=T)
cor(Y)
L <- matrix(rnorm(k*n), ncol=k, byrow = T)
Y <- M + L%*%W + matrix(rnorm(n*d,0,noise.sd), ncol=d, byrow=T)
cor(Y)
x <- rnorm(k*n)
x
acf(x)
acf(rnorm(k*n*100))
q <- acf(rnorm(k*n*100))
q
n = 1000 # number of observations
k = 2   # number of latent dimensions
d = 6
noise.sd = rep(0, d) # c(5,4,3,2,1)
m = rep(0, d)
W <- rbind(c(1,1,1,1,0,0), c(0,0,1,1,1,1))
M <- matrix(rep(m, each=n), ncol=d)
L <- matrix(rnorm(k*n), ncol=k, byrow = T)
Y <- M + L%*%W + matrix(rnorm(n*d,0,noise.sd), ncol=d, byrow=T)
cor(Y) # yikes, R's pseudo-random number generated makes correlations.
L <- matrix(rnorm(k*n), ncol=k, byrow = F)
Y <- M + L%*%W + matrix(rnorm(n*d,0,noise.sd), ncol=d, byrow=T)
cor(Y) # yikes, R's pseudo-random number generated makes correlations.
# multivariate data.
library(tidyverse)
poke <- read_csv('http://vulstats.ucsd.edu/data/Pokemon.csv')
menu <- read_csv('http://vulstats.ucsd.edu/data/menu.csv')
glimpse(menu)
menu <- menu[,-c(1:3)]
library(GGally)
ggpairs(menu)
# true forward loadings:
W <- rbind(c(1,1,1,0,0,0),
c(0,0,0,1,1,1))
# observable measure stats: noise, scale, mean
noise.sd = rep(0, d)# rep(0, d) # c(5,4,3,2,1)
Y.scale = rep(1, d) # (1:d)^2 #
Y.mean = rep(0, d) # c(100,0,-100,-100,0,100)
L <- matrix(rnorm(k*n), ncol=k) # generate latent scores.
Y <- L%*%W  # project latent onto observed
Y <- Y + matrix(rnorm(n*d,0,noise.sd), ncol=d, byrow=T) # add noise
Y <- Y*matrix(rep(Y.scale, each=n), ncol=d) # scale observed
Y <- Y + matrix(rep(Y.mean, each=n), ncol=d) # add means
ggpairs(as.data.frame(Y))
L <- matrix(rnorm(k*n), ncol=k) # generate latent scores.
Y <- L%*%W  # project latent onto observed
# part 1: low-d linear projections / latent variables.
# SVD, PCA, PPCA, FA, ICA
n = 100 # number of observations
k = 2   # number of latent dimensions
d = 6   # number of observed dimensions
# true forward loadings:
W <- rbind(c(1,1,1,0,0,0),
c(0,0,0,1,1,1))
# observable measure stats: noise, scale, mean
noise.sd = rep(0, d)# rep(0, d) # c(5,4,3,2,1)
Y.scale = rep(1, d) # (1:d)^2 #
Y.mean = rep(0, d) # c(100,0,-100,-100,0,100)
L <- matrix(rnorm(k*n), ncol=k) # generate latent scores.
Y <- L%*%W  # project latent onto observed
Y <- Y + matrix(rnorm(n*d,0,noise.sd), ncol=d, byrow=T) # add noise
Y <- Y*matrix(rep(Y.scale, each=n), ncol=d) # scale observed
Y <- Y + matrix(rep(Y.mean, each=n), ncol=d) # add means
# what have we wrought?
cor(Y)
ggpairs(as.data.frame(Y))
ggpairs(as.data.frame(Y))
# svd: singular value decomposition of data matrix.
# will be really influenced by the means! (generally: center and scale before using)
a.svd <- svd(Y)
str(a.svd)
head(a.svd$u) # values on latent dimensions
head(a.svd$u) # values on latent dimensions
head(a.svd$u, 10) # values on latent dimensions
apply(a.svd$u, 2, function(x){sum(x^2)})
plot(a.svd$d)  # scale of latent dimensions: sd of latent variables.
plot(a.svd$d^2/sum(a.svd$d^2)) # percent overall variance accounted for by each.
a.svd$v # loadings: how each latent dimension projects onto observed dimensions.
a.svd$v # loadings: how each latent dimension projects onto observed dimensions.
# e.g., a.svd$v[,1] is how you go from u[,1]*d[1] to y
# how to get the original data?
plot(a.svd$u[,1:2])
plot(L)
cor(L, a.svd$u)
cor(L, a.svd$u)
cor(L, a.svd$u)
# what have we wrought?
cor(Y)
# PCA: solving the same problem, often via SVD (or via covariance matrix)
# but build in centering
a.pca <- prcomp(Y, center=T, scale=F) # just svd with centering (scaling not usually default)
plot(a.pca$sdev)
a.pca$rotation
a.pca$rotation
a.pca$rotation
Y.mean = c(100,0,-100,-100,0,100) #rep(0, d) # c(100,0,-100,-100,0,100)
L <- matrix(rnorm(k*n), ncol=k) # generate latent scores.
Y <- L%*%W  # project latent onto observed
Y <- Y + matrix(rnorm(n*d,0,noise.sd), ncol=d, byrow=T) # add noise
Y <- Y*matrix(rep(Y.scale, each=n), ncol=d) # scale observed
Y <- Y + matrix(rep(Y.mean, each=n), ncol=d) # add means
# what have we wrought?
cor(Y)
# svd: singular value decomposition of data matrix.
# will be really influenced by the means! (generally: center and scale before using)
a.svd <- svd(Y)
plot(a.svd$d)  # scale of latent dimensions: sd of latent variables.
a.svd$v # loadings: how each latent dimension projects onto observed dimensions.
a.svd$v # loadings: how each latent dimension projects onto observed dimensions.
# PCA: solving the same problem, often via SVD (or via covariance matrix)
# but build in centering
a.pca <- prcomp(Y, center=T, scale=F) # just svd with centering (scaling not usually default)
plot(a.pca$sdev)
poke <- read_csv('http://vulstats.ucsd.edu/data/Pokemon.csv')
glimpse(poke)
ggpairs(poke[,7:11])
ggpairs(poke[,7:11])
a.pca <- prcomp(poke[,7:11], center=T, scale=T) # just svd with centering (scaling not usually default)
plot(a.pca$sdev)
a.pca$rotation
a.pca <- prcomp(poke[,6:11], center=T, scale=T) # just svd with centering (scaling not usually default)
a.pca$rotation
round(a.pca$rotation, 2)
plot(a.pca$sdev)
plot(a.pca$sdev^2/sum(a.pca$sdev^2))
loadings(a.pca)
summary(a.pca)
a.pca$x
str(a.pca$x)
glimpse(poke)
cbind(a.pca$x, poke$Name)
cbind(a.pca$x, poke$Name) %>% as.tibble()
a.pca$x %>% as.tibble() %>% mutate(name=poke$Name)
a.pca$x %>% as.tibble() %>% mutate(name=poke$Name) %>%
ggplot(aes(x=PC1, y=PC2))+geom_text(label=name)
a.pca$x %>% as.tibble() %>% mutate(pname=poke$Name) %>%
ggplot(aes(x=PC1, y=PC2))+geom_text(label=pname)
a.pca$x %>% as.tibble() %>% mutate(pname=poke$Name)
a.pca$x %>% as.tibble() %>% mutate(pname=poke$Name) %>%
ggplot(aes(x=PC1, y=PC2))+geom_text(aes(label=pname))
a.pca$x %>% as.tibble() %>% mutate(pname=poke$Name) %>%
slice(1:25) %>%
ggplot(aes(x=PC1, y=PC2))+geom_text(aes(label=pname))
glimpse(menu)
# true forward loadings:
W <- rbind(c(1,1,0,0,0,0),
c(0,0,0,0,1,1))
# observable measure stats: noise, scale, mean
noise.sd = rep(1, d)# rep(0, d) # c(5,4,3,2,1)
Y.scale = rep(1, d) # (1:d)^2 #
Y.mean = c(100,0,-100,-100,0,100) #rep(0, d) # c(100,0,-100,-100,0,100)
L <- matrix(rnorm(k*n), ncol=k) # generate latent scores.
Y <- L%*%W  # project latent onto observed
Y <- Y + matrix(rnorm(n*d,0,noise.sd), ncol=d, byrow=T) # add noise
Y <- Y*matrix(rep(Y.scale, each=n), ncol=d) # scale observed
Y <- Y + matrix(rep(Y.mean, each=n), ncol=d) # add means
# PCA: solving the same problem, often via SVD (or via covariance matrix)
# but build in centering
a.pca <- prcomp(Y, center=T, scale=F) # just svd with centering (scaling not usually default)
plot(a.pca$sdev)
a.pca$rotation
a.pca$rotation
# observable measure stats: noise, scale, mean
noise.sd = rep(3, d)# rep(0, d) # c(5,4,3,2,1)
Y.scale = rep(1, d) # (1:d)^2 #
Y.mean = c(100,0,-100,-100,0,100) #rep(0, d) # c(100,0,-100,-100,0,100)
L <- matrix(rnorm(k*n), ncol=k) # generate latent scores.
Y <- L%*%W  # project latent onto observed
Y <- Y + matrix(rnorm(n*d,0,noise.sd), ncol=d, byrow=T) # add noise
Y <- Y*matrix(rep(Y.scale, each=n), ncol=d) # scale observed
Y <- Y + matrix(rep(Y.mean, each=n), ncol=d) # add means
# what have we wrought?
cor(Y)
# PCA: solving the same problem, often via SVD (or via covariance matrix)
# but build in centering
a.pca <- prcomp(Y, center=T, scale=F) # just svd with centering (scaling not usually default)
plot(a.pca$sdev)
a.pca$rotation
a.pca$rotation
# PPCA and factor analysis are generative models, in that they allow for noise
# they also estimate a fixed number of latent components.
library(pcaMethods) # obnoxiously requires bioconductor details to install.
# ppca: k components plus iid noise with the same sd in all dimensions.
a.ppca <- pca(Y, method = 'ppca', nPcs = 2, center=T)
a.ppca@loadings
# part 1: low-d linear projections / latent variables.
# SVD, PCA, PPCA, FA, ICA
n = 1000 # number of observations
k = 2   # number of latent dimensions
d = 2   # number of observed dimensions
# true forward loadings:
W <- matrix(rnorm(d*k), ncol=d)
# observable measure stats: noise, scale, mean
noise.sd = rep(0, d)# rep(0, d) # c(5,4,3,2,1)
Y.scale = rep(1, d) # (1:d)^2 #
Y.mean = rep(0, d) # c(100,0,-100,-100,0,100)
Y <- L%*%W  # project latent onto observed
Y <- Y + matrix(rnorm(n*d,0,noise.sd), ncol=d, byrow=T) # add noise
Y <- Y*matrix(rep(Y.scale, each=n), ncol=d) # scale observed
Y <- Y + matrix(rep(Y.mean, each=n), ncol=d) # add means
plot(Y[,1], Y[,2])
# true forward loadings:
W <- matrix(rnorm(d*k), ncol=d)
# observable measure stats: noise, scale, mean
noise.sd = rep(0, d)# rep(0, d) # c(5,4,3,2,1)
Y.scale = rep(1, d) # (1:d)^2 #
Y.mean = rep(0, d) # c(100,0,-100,-100,0,100)
L <- matrix(rnorm(k*n)^3, ncol=k) # generate latent scores.
Y <- L%*%W  # project latent onto observed
Y <- Y + matrix(rnorm(n*d,0,noise.sd), ncol=d, byrow=T) # add noise
Y <- Y*matrix(rep(Y.scale, each=n), ncol=d) # scale observed
Y <- Y + matrix(rep(Y.mean, each=n), ncol=d) # add means
plot(Y[,1], Y[,2])
# true forward loadings:
W <- matrix(rnorm(d*k), ncol=d)
# observable measure stats: noise, scale, mean
noise.sd = rep(0, d)# rep(0, d) # c(5,4,3,2,1)
Y.scale = rep(1, d) # (1:d)^2 #
Y.mean = rep(0, d) # c(100,0,-100,-100,0,100)
L <- matrix(rnorm(k*n)^3, ncol=k) # generate latent scores.
Y <- L%*%W  # project latent onto observed
Y <- Y + matrix(rnorm(n*d,0,noise.sd), ncol=d, byrow=T) # add noise
Y <- Y*matrix(rep(Y.scale, each=n), ncol=d) # scale observed
Y <- Y + matrix(rep(Y.mean, each=n), ncol=d) # add means
plot(Y[,1], Y[,2])
# true forward loadings:
W <- matrix(rnorm(d*k), ncol=d)
# observable measure stats: noise, scale, mean
noise.sd = rep(0, d)# rep(0, d) # c(5,4,3,2,1)
Y.scale = rep(1, d) # (1:d)^2 #
Y.mean = rep(0, d) # c(100,0,-100,-100,0,100)
L <- matrix(rnorm(k*n)^3, ncol=k) # generate latent scores.
Y <- L%*%W  # project latent onto observed
Y <- Y + matrix(rnorm(n*d,0,noise.sd), ncol=d, byrow=T) # add noise
Y <- Y*matrix(rep(Y.scale, each=n), ncol=d) # scale observed
Y <- Y + matrix(rep(Y.mean, each=n), ncol=d) # add means
plot(Y[,1], Y[,2])
a.pca <- prcomp(Y)
plot(a.pca$x)
a.ica <- fastICA(Y, 2)
library(fastICA)
a.ica <- fastICA(Y, 2)
str(a.ica)
plot(a.ica$S)
glimpse(poke)
Y = as.matrix(poke[,6:11])
head(Y)
m.res <- manova(Y~T1+T2+L1)
T1 <- poke[[3]]
T2 <- poke[[4]]
L1 <- poke[[13]]
m.res <- manova(Y~T1+T2+L1)
summary.manova(m.res)
coef(m.res)
coef(m.res)
summary.manova(m.res)
summary.aov(m.res)
tmp <- summary.manova(m.res)
tmp
str(tmp)
tmp$SS$Residuals
# canonical correlation:
# multivariate X and Y,
# find linear combinations of X and Y that are correlated
cancor(Y, L)
# canonical correlation:
# multivariate X and Y,
# find linear combinations of X and Y that are correlated
X <- poke[,6:8]
Y <- poke[,9:11]
X
str(X)
cancor(Y, L)
cancor(X, Y)
df <- data.frame(category = c(rep('A', n), rep('B', n)),
y1,y2)
means = list('A' = c(0,0), 'B'=c(1,1))
n = 10
y1 = rnorm(n*2)
y2 = -1*y1
y1 = y1+rnorm(n*2)
y2 = y2+rnorm(n*2)
df <- data.frame(category = c(rep('A', n), rep('B', n)),
y1,y2)
df
# manova
library(tidyverse)
means = rbind(c(0,0), c(1,1))
means
rownames(means) <- c('A', 'B')
means
df <- df %>% mutate(y1 = y1+means[category,1])
df <- df %>% mutate(y1 = y1+means[category,1],
y2 = y2+means[category,2])
df <- data.frame(category = c(rep('A', n), rep('B', n)),
y1,y2)
df <- df %>% mutate(y1 = y1+means[category,1],
y2 = y2+means[category,2])
df %>% ggplot(aes(x=y1,y=y2,color=category))+geom_point()
means = rbind(c(0,0), c(1,1))
rownames(means) <- c('A', 'B')
n = 100
s = 0.01
y1 = rnorm(n*2)
y2 = -1*y1
y1 = y1+rnorm(n*2)*s
y2 = y2+rnorm(n*2)*s
df <- data.frame(category = c(rep('A', n), rep('B', n)),
y1,y2)
df <- df %>% mutate(y1 = y1+means[category,1],
y2 = y2+means[category,2])
df %>% ggplot(aes(x=y1,y=y2,color=category))+geom_point()
m.res = manova(data=df, cbind(y1,y2)~category)
m.res
summary(m.res)
summary.aov(m.res)
means = rbind(c(0,0), c(1,1))
rownames(means) <- c('A', 'B')
n = 10
s = 0.01
y1 = rnorm(n*2)
y2 = -1*y1
y1 = y1+rnorm(n*2)*s
y2 = y2+rnorm(n*2)*s
df <- data.frame(category = c(rep('A', n), rep('B', n)),
y1,y2)
df <- df %>% mutate(y1 = y1+means[category,1],
y2 = y2+means[category,2])
df %>% ggplot(aes(x=y1,y=y2,color=category))+geom_point()
m.res = manova(data=df, cbind(y1,y2)~category)
summary.aov(m.res)
summary.manova(m.res)
df <- expand.grid(x=c(0,1), y=c(0,1))
df
library(tidyverse)
df <- expand.grid(x=c(0,1), y=c(0,1)) %>%
mutate(n = c(30, 40, 0, 30))
df
?repeat
?repeat
;
repeat()
?repeat()
which(repeat)
df <- df[rep(1:4, each=df$n),]
df <- df[rep(1:4, df$n),]
df$n
df <- expand.grid(x=c(0,1), y=c(0,1)) %>%
mutate(n = c(30, 40, 0, 30))
df <- df[rep(1:4, df$n),]
df
cor(df$x, df$y)
c(1, 3, 6, 10, 15)
1:10
1:5
n = 1:5
n*(n+1)/2
bls <- read_csv('~/TEACHING/2017.201ab/vulstats/data/BLS.2016.csv')
library(tidyverse)
bls <- read_csv('~/TEACHING/2017.201ab/vulstats/data/BLS.2016.csv')
str(bls)
glimpse(bls)
bls $>$ arrange(desc(all.n))
bls  %>%  arrange(desc(all.n))
bls  %>%  select(occupation, all.n) %>% arrange(desc(all.n))
bls  %>%  select(Occupation, all.n) %>% arrange(desc(all.n))
grep('Marine', bls$Occupation)
bls[grep('Marine', bls$Occupation),]
bls[grep('marine', bls$Occupation),]
bls[grep('biol', bls$Occupation),]
bls[grep('Biol', bls$Occupation),]
exp(3.813)
source('~/PROJECTS/multicolor-binding/github/analysis/models.R')
setwd('~/PROJECTS/multicolor-binding/github/analysis/')
source('~/PROJECTS/multicolor-binding/github/analysis/models.R')
s = 1
px = prob.loc(s)
X1 <- outer(c(px, rep(0,5)), rep(1/10, 10), '*')
X1
sum(X1)
X2 <- outer(rep(1/10, 10), c(rep(0,5), px), '*')
sum(X2)
X2
bias = 0.5
X = X1*bias + X2*(1-bias)
sum(X)
X
gen_rep(X, 0.2)
source('~/PROJECTS/multicolor-binding/github/analysis/models.R')
gen_rep(X, 0.2)
heatmap(D, Rowv = NA, Colv = NA, scale = 'none')
heatmap(gen_rep(sample_part_guess(0.05), 0.2), Rowv = NA, Colv = NA, scale = 'none')
heatmap(gen_rep(sample_part_guess(0.05), 0), Rowv = NA, Colv = NA, scale = 'none')
